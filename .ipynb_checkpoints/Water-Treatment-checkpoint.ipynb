{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import copy\n",
    "import time\n",
    "import itertools\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_watertreatment=pd.read_csv('data files/watertreatment-orig/water-treatment.data', low_memory=False)\n",
    "pd.set_option('display.float_format', lambda x:'%f'%x)\n",
    "original_watertreatment.columns=['Date', 'Q-E', 'ZN-E', 'PH-E', 'DBO-E', 'DQO-E', 'SS-E', 'SSV-E', 'SED-E',\n",
    "                                 'COND-E', 'PH-P', 'DBO-P', 'SS-P', 'SSV-P', 'SED-P', 'COND-P', 'PH-D', 'DBO-D',\n",
    "                                 'DQO-D', 'SS-D', 'SSV-D', 'SED-D', 'COND-D', 'PH-S', 'DBO-S', 'DQO-S', 'SS-S',\n",
    "                                 'SSV-S', 'SED-S', 'COND-S', 'RD-DBO-P', 'RD-SS-P', 'RD-SED-P', 'RD-DBO-S',\n",
    "                                 'RD-DQO-S', 'RD-DBO-G',  'RD-DQO-G',  'RD-SS-G',  'RD-SED-G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_watertreatment['Date']=original_watertreatment['Date'].str[2:]\n",
    "original_watertreatment['Date']=pd.to_datetime(original_watertreatment['Date'])\n",
    "original_watertreatment=original_watertreatment.set_index(pd.DatetimeIndex(original_watertreatment['Date']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_dataframe(dataframe):\n",
    "    x=copy.deepcopy(dataframe)\n",
    "    min_max_scaler=preprocessing.MinMaxScaler()\n",
    "    x_scaled=min_max_scaler.fit_transform(x)\n",
    "    normalised_dataframe=pd.DataFrame(x_scaled, columns=dataframe.columns, index=dataframe.index)\n",
    "    return normalised_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering_initial(k=1):\n",
    "    # Initial points\n",
    "    centroids={}\n",
    "    centroids_step = {\n",
    "    i+1: [np.random.random(), np.random.random()]\n",
    "    for i in range(k)\n",
    "    }\n",
    "    centroids[0]=centroids_step\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, cx, y, cy):\n",
    "    distance=np.sqrt((x-cx)**2 + (y-cy)**2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviation(x, cx, y, cy):\n",
    "    deviation=(x-cx)+(y-cy)\n",
    "    return deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering_assignment(dataframe, x, y, centroids, k, i):\n",
    "    assignment=copy.deepcopy(dataframe)\n",
    "    for ik in range(1, k+1):\n",
    "        assignment['distance_from_{}'.format(ik)]=euclidean_distance(dataframe[x], centroids[i][ik][0], dataframe[y], centroids[i][ik][0])\n",
    "        assignment['deviation_from_{}'.format(ik)]=deviation(dataframe[x], centroids[i][ik][0], dataframe[y], centroids[i][ik][0])\n",
    "    centroid_distance_cols=['distance_from_{}'.format(ik) for ik in centroids[i].keys()]\n",
    "    assignment['closest']=assignment.loc[:, centroid_distance_cols].idxmin(axis=1)\n",
    "    assignment['closest']=assignment['closest'].map(lambda x: int(x.lstrip('distance_from_')))\n",
    "    return assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering_update_centroids(dataset, x, y, k, i, centroids):\n",
    "    centroids[i]=copy.deepcopy(centroids[i-1])\n",
    "    for ik in range(1, k+1):\n",
    "        centroids[i][ik]=[np.mean(dataset[dataset['closest']==ik][x]), np.mean(dataset[dataset['closest']==ik][y])]\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def within_cluster_sum_of_square_errors(dataset, k, i):\n",
    "    results={}\n",
    "    wss=0.0\n",
    "    for ik in range(1, k+1):\n",
    "        temp=0.0\n",
    "        cluster=dataset['closest']==ik\n",
    "        cluster_data=dataset[cluster]['deviation_from_{}'.format(ik)].replace(np.nan, 0.0)\n",
    "        count=cluster_data.count()\n",
    "        cluster_data_2=np.power(cluster_data, 2)\n",
    "        cluster_sum=cluster_data_2.sum()\n",
    "        if cluster_sum==0.0:\n",
    "            temp=0.0\n",
    "        else:\n",
    "            temp=cluster_sum/count\n",
    "        wss+=temp\n",
    "    return wss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_centroid_change(centroids, k, i):\n",
    "    result=False\n",
    "    for ik in range(1, k+1):\n",
    "        x=centroids[i][ik][0]==centroids[i-1][ik][0]\n",
    "        y=centroids[i][ik][1]==centroids[i-1][ik][1]\n",
    "        if x==False or y==False:\n",
    "            result=True\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering(dataframe, x, y, k=1):\n",
    "    kmeans=copy.deepcopy(dataframe)\n",
    "    centroids=kmeans_clustering_initial(k)\n",
    "    kmeans=kmeans_clustering_assignment(kmeans, x, y, centroids, k, 0)\n",
    "    i=0\n",
    "    while True:\n",
    "        i+=1\n",
    "        centroids = kmeans_clustering_update_centroids(kmeans, x, y, k, i, centroids)\n",
    "        kmeans = kmeans_clustering_assignment(kmeans, x, y, centroids, k, i)\n",
    "        if no_centroid_change(centroids, k, i):\n",
    "            break;\n",
    "    return kmeans, within_cluster_sum_of_square_errors(kmeans, k, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_kmeans(dataframe, x, y):\n",
    "    plots={}\n",
    "    seeds={}\n",
    "    count=0\n",
    "    total_plot_time=0\n",
    "    np.random.seed(12345)\n",
    "    for j in range(0, 25):\n",
    "        seeds[j]=int(np.random.random()*1000)\n",
    "    for i in range(1, 11):\n",
    "        j_plots={}\n",
    "        for j in range(0, 25):\n",
    "            start = time.time()\n",
    "            np.random.seed(seeds[j])\n",
    "            j_plot, j_wss=kmeans_clustering(dataframe, x, y, i)\n",
    "            j_plots[j_wss]=j_plot\n",
    "            end = time.time()\n",
    "            elapsed = end - start\n",
    "            total_plot_time+=elapsed\n",
    "            count+=1\n",
    "            #print(\"Plot {} - time elapsed - {} - total time elapsed - {} - wss - {}\".format(count, elapsed, total_plot_time, j_wss))\n",
    "        wss = sorted(j_plots)[0]\n",
    "        #print(wss)\n",
    "        plot = j_plots[wss]\n",
    "        plots[wss] = plot\n",
    "    #print(\"Total time elapsed - {}\".format(total_plot_time))\n",
    "    return plots[sorted(plots)[0]], total_plot_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Column Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_combinations=[]\n",
    "column_combinations=list(itertools.combinations(original_watertreatment.columns.drop('Date'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlate Coefficients to Rule Out Unneeded Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_to_calculate=[]\n",
    "column_combos_count={}\n",
    "for dataset_key, dataset in dataset_combinations.items():\n",
    "    for combo in column_combinations:\n",
    "        x=dataset[combo[0]]\n",
    "        y=dataset[combo[1]]\n",
    "        # result[0] is a value between -1 and 1\n",
    "        # The null hypothesis is that the two columns are not correlated\n",
    "        # The result is a number between 0 and one that represents the probability\n",
    "        # that the data would have arisen if the null hypothesis is true\n",
    "        result=scipy.stats.kendalltau(x, y)[0]\n",
    "        x_r=result>0.9\n",
    "        if(x_r):\n",
    "            plots_to_calculate.append((dataset_key, dataset, combo[0], combo[1]))\n",
    "            if '{}-{}'.format(combo[0], combo[1]) in column_combos_count:\n",
    "                column_combos_count['{}-{}'.format(combo[0], combo[1])]+=1\n",
    "            else:\n",
    "                column_combos_count['{}-{}'.format(combo[0], combo[1])]=1\n",
    "            #print('{}-{}-{}'.format(dataset_key, combo[0], combo[1]))\n",
    "print(len(plots_to_calculate))\n",
    "for key, value in column_combos_count.items():\n",
    "    print('{}-{}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots={}\n",
    "total_time=0\n",
    "num=len(plots_to_calculate)\n",
    "num_left=num\n",
    "time_left_estimate=total_time\n",
    "for entry in plots_to_calculate:\n",
    "    dataset_key=entry[0]\n",
    "    dataset=entry[1]\n",
    "    x=entry[2]\n",
    "    y=entry[3]\n",
    "    plots['{}_{}_{}'.format(dataset_key, x, y)], plot_time=do_kmeans(dataset, x, y)\n",
    "    total_time+=plot_time\n",
    "    num_left-=1\n",
    "    average_completion_time=total_time/(num-num_left)\n",
    "    time_left_estimate=(num_left*(average_completion_time))\n",
    "    print('Completed {}/{} plots. Average plot completion time is {}. Estimated time remaining is {}'.format((num-num_left), num, average_completion_time, time_left_estimate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hs_hmax_dir_tp_months_sst_months_plot, wss1=do_kmeans(normalised_wavedata_dir_tp_months_sst_months, 'Tz', 'SST')\n",
    "##sns.lmplot('Tz', 'SST', data=hs_hmax_dir_tp_months_sst_months_plot, fit_reg=False, hue='closest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hs_tz_dir_tp_months_sst_months_plot, wss2=do_kmeans(normalised_wavedata_dir_tp_months_sst_months, 'Hs', 'Tz')\n",
    "##sns.lmplot('Hs', 'Tz', data=hs_tz_dir_tp_months_sst_months_plot, fit_reg=False, hue='closest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hs_tp_dir_tp_months_sst_months_plot, wss3=do_kmeans(normalised_wavedata_dir_tp_months_sst_months, 'Hs', 'Tp')\n",
    "##sns.lmplot('Hs', 'Tp', data=hs_tp_dir_tp_months_sst_months_plot, fit_reg=False, hue='closest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hs_dir_tp_dir_tp_months_sst_months_plot, wss4=do_kmeans(normalised_wavedata_dir_tp_months_sst_months, 'Hs', 'Dir_Tp TRUE')\n",
    "##sns.lmplot('Hs', 'Dir_Tp TRUE', data=hs_dir_tp_dir_tp_months_sst_months_plot, fit_reg=False, hue='closest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hs_sst_dir_tp_months_sst_months_plot, wss5=do_kmeans(normalised_wavedata_dir_tp_months_sst_months, 'Hs', 'SST')\n",
    "##sns.lmplot('Hs', 'SST', data=hs_sst_dir_tp_months_sst_months_plot, fit_reg=False, hue='closest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
